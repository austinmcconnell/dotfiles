**IMPORTANT: Branch Validation Required**
Before proceeding, verify the current git branch:
```bash
git branch --show-current
```

This analysis should ONLY be performed on `main` or `master` branches. If currently on a different branch, abort the analysis and inform the user that schema analysis should be done from the main branch.

**Prerequisite Check:**
This analysis requires the following prerequisite analysis to be completed first.

Check for required file:
- `analysis/project-analysis.md`

If the file is missing, run the prerequisite analysis first:
- Missing project-analysis.md? Run: `project-analysis`

**If the prerequisite file is missing, abort this analysis and complete the prerequisite first.**

**Schema and Data Model Analysis:**
Analyze the data models, database schemas, and API data structures in this repository.

**Read Prerequisite Analysis:**
Read `analysis/project-analysis.md` to understand the project context, purpose, and technology stack before proceeding with the schema analysis.

Please:

1. **Database Schema Analysis**
   - Identify database technologies in use (PostgreSQL, MySQL, SQLite, etc.)
   - Document table structures, column types, and constraints
   - Analyze primary keys, foreign keys, and relationships
   - Document indexes, unique constraints, and performance optimizations
   - Note any database migrations or schema versioning approaches

2. **ORM and Model Classes**
   - Identify ORM frameworks (Django ORM, SQLAlchemy, ActiveRecord, etc.)
   - Document model class definitions and their attributes
   - Analyze model relationships (one-to-one, one-to-many, many-to-many)
   - Note any model validations, custom methods, or business logic
   - Document any model inheritance or abstract base classes

3. **API Data Models**
   - Identify API data formats (JSON schemas, GraphQL types, Protocol Buffers, etc.)
   - Document request/response data structures
   - Analyze data serialization and deserialization patterns
   - Note any API versioning strategies for data models
   - Document validation rules and constraints for API data

4. **Data Relationships and Constraints**
   - Map relationships between different data entities
   - Document referential integrity constraints
   - Analyze cascade behaviors and deletion policies
   - Note any soft delete patterns or audit trails
   - Document any denormalization or data duplication patterns

5. **Data Validation and Business Rules**
   - Identify validation rules at database, model, and API levels
   - Document business logic embedded in data models
   - Analyze data transformation and computed fields
   - Note any data lifecycle management (archiving, purging, etc.)
   - Document any data privacy or compliance considerations

6. **Cross-Layer Consistency**
   - Compare database schemas with ORM model definitions
   - Validate API data models against internal data structures
   - Identify any mismatches or inconsistencies between layers
   - Document data mapping and transformation patterns
   - Note any data format conversions or adaptations

7. **Data Access Patterns**
   - Analyze common query patterns and data access methods
   - Document any custom query builders or data access layers
   - Identify any caching strategies for data models
   - Note any bulk operations or batch processing patterns
   - Document any data aggregation or reporting structures

**Focus Areas:**
- What data entities and relationships exist in the system?
- How are data models structured and organized?
- What constraints and validations are in place?
- How consistent are data models across different layers?
- What are the data access and manipulation patterns?
- How is data integrity and consistency maintained?

**Output Requirements:**

1. **Save to File**: Write the complete analysis to `analysis/schema-analysis.md`
2. **Metadata Header**: Include the following metadata at the top of the file:

```markdown
# Schema and Data Model Analysis

**Generated:** [YYYY-MM-DD HH:MM:SS UTC]
**Branch:** [current branch name]
**HEAD Commit:** [full commit hash]
**Repository:** [repository name/path]

---
```

3. **Analysis Content**: Provide a comprehensive overview covering:
   - Database schema structure and constraints
   - ORM and model class definitions
   - API data models and formats
   - Data relationships and referential integrity
   - Validation rules and business logic
   - Cross-layer consistency and mapping
   - Data access patterns and optimizations
   - Areas of concern or improvement opportunities

**Commands to Gather Metadata:**
```bash
# Get current branch
git branch --show-current

# Get HEAD commit hash
git rev-parse HEAD

# Get repository name
basename "$(git rev-parse --show-toplevel)"

# Get current timestamp
date -u +"%Y-%m-%d %H:%M:%S UTC"
```

**Additional Analysis Commands:**
```bash
# Look for database-related files
find . -name "*.sql" -o -name "*migration*" -o -name "*schema*" | head -20

# Look for model files (common patterns)
find . -name "*model*" -o -name "*entity*" -o -name "*schema*" | grep -E "\.(py|js|ts|rb|java|go)$" | head -20

# Search for ORM and database patterns
grep -r -i "class.*model\|table\|schema\|migration" --include="*.py" --include="*.js" --include="*.ts" --include="*.rb" --include="*.java" . | head -20

# Look for API schema files
find . -name "*.json" -o -name "*.yaml" -o -name "*.yml" | grep -i "schema\|api\|spec" | head -10
```

**Update Strategy:**
If `analysis/schema-analysis.md` already exists:
1. Read the existing file to understand previous schema analysis
2. Note what has changed since the last analysis (compare commit hashes)
3. Update the analysis with new schema insights while preserving valuable context
4. Update the metadata header with new timestamp and commit hash

**File Management:**
- The `analysis/*.md` files are automatically ignored by git (global gitignore)
- This allows analysis files to be updated over time without cluttering the repository
- Files can be manually committed if you want to track schema evolution over time

Focus on understanding the current data model structure and relationships rather than suggesting major schema changes.
